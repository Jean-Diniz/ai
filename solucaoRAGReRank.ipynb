{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_cohere import CohereRerank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.1,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregar pdf\n",
    "\n",
    "pdf_link = \"lotus.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_link, extract_images=False)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'lotus.pdf', 'page': 0, 'page_label': '1', 'start_index': 0}, page_content='Pavan Emani\\nSummary\\nThe article discusses the transition from Text2SQL and Retrieval-Augmented\\nGeneration (RAG) to Table-Augmented Generation (TAG) as a more effective\\nmethod for AI-driven data queries, leveraging the LOTUS framework to integrate\\nAI and database capabilities.\\nAbstract\\nThe article \"Goodbye, Text2SQL: Why Table-Augmented Generation (TAG) is\\nthe Future of AI-Driven Data Queries!\" explores the limitations of current AI\\nmethods like Text2SQL and Retrieval-Augmented Generation (RAG) in handling\\ncomplex data queries. It argues that TAG, a new approach developed by\\nresearchers from Stanford and Berkeley, overcomes these limitations by\\ncombining AI\\'s semantic reasoning with the computational power of databases.\\nTAG utilizes a multi-step process involving query synthesis, execution, and\\nanswer generation, enhanced by the LOTUS framework, which allows for\\nsemantic queries over structured and unstructured data. This integration enables\\nmore sophisticated and context-rich responses to user queries, addressing the\\ncritical gap in real-world applicability of AI in data analysis.\\nOpinions\\nText2SQL and RAG methods are inadequate for complex queries, as they\\neither translate queries into SQL or perform simple lookups without capturing\\nreal-world complexity.\\nThe inability of existing methods to effectively combine AI reasoning with\\ndatabase computational power is a major bottleneck for deriving actionable\\ninsights from data.\\nTAG is presented as a superior alternative, capable of generating complex\\nqueries that incorporate multiple data sources and types, and performing\\nadvanced operations like sentiment analysis.\\nSearch Translate to English'), Document(metadata={'source': 'lotus.pdf', 'page': 1, 'page_label': '2', 'start_index': 0}, page_content=\"Use the OpenAI o1 models for free at OpenAI01.net (10 times a day for free)!\\nGoodbye, Text2SQL: Why Table-Augmented\\nGeneration (TAG) is the Future of AI-Driven Data\\nQueries!\\nExploring the Future of Natural Language Queries with Table-\\nAugmented Generation.\\nThe LOTUS framework is crucial for TAG's effectiveness, as it integrates AI\\ncapabilities with database systems, enabling semantic queries and optimized\\nquery execution.\\nThe author believes that TAG, powered by LOTUS, represents a significant\\nadvancement in AI-driven data querying, offering flexibility, customization,\\nand the ability to provide comprehensive answers.\\nTranslate to\"), Document(metadata={'source': 'lotus.pdf', 'page': 2, 'page_label': '3', 'start_index': 0}, page_content='Photo by Choong Deng Xiang on Unsplash\\nImagine you’re a business analyst, trying to understand why your company’s sales\\ndropped last quarter. You query your database with a simple natural language\\nquestion: “Why did sales drop last quarter?” The ideal scenario would be that the AI\\nsystem instantly provides you with a context-rich, insightful answer — something\\nthat ties together all relevant data points, trends, and market insights. However, the\\nreality is far from ideal.\\nCurrent AI methods for querying databases, such as Text2SQL and Retrieval-\\nAugmented Generation (RAG), fall significantly short. These models are limited by\\ntheir design, either only interpreting natural language as SQL queries or relying on\\nsimple lookups that fail to capture the complexity of real-world questions.\\nWhy does this matter? Using Natural Language to query SQL databases is the new\\nnorm ever since LLMs started capturing the limelight! Businesses today are\\ndrowning in data but starving for insights. The inability of existing methods to\\neffectively leverage both AI’s semantic reasoning and databases’ computational\\npower is a major bottleneck in making data truly actionable. It’s clear that we need a\\nnew approach — one that can understand and answer the wide range of questions\\nreal users want to ask.\\nBut using Natural language in such a scenario comes with challenges:\\nText2SQL: This approach is designed to convert natural language questions into\\nSQL queries. While it works well for straightforward questions like “What were\\nthe total sales last quarter?” it fails when questions require more complex\\nreasoning or knowledge that is not explicitly stored in the database. For example,\\na question like “Which customer reviews of product X are positive?” requires\\nsentiment analysis over text data — a capability outside the scope of SQL\\nqueries.\\nRetrieval-Augmented Generation (RAG): RAG models attempt to use AI to\\nfind relevant data records from a database, but they are limited to point lookups\\nand cannot handle complex computations. They often fail to provide accurate\\nTranslate to'), Document(metadata={'source': 'lotus.pdf', 'page': 3, 'page_label': '4', 'start_index': 0}, page_content='answers when data volume is high, or when the question requires reasoning over\\nmultiple data points.\\nConsider a business scenario where you need to understand trends from customer\\nreviews, sales data, and market sentiment all at once. Text2SQL cannot handle free-\\ntext data. And not to forget hallucinations! RAG addresses this to some extent, but its\\ninefficient with large datasets and can provide inaccurate or incomplete answers,\\nespecially when it doesn’t have the knowledge of target database or it cannot exactly\\ntranslate the user intent into a functioning SQL!\\nAnd so, these approaches leave a large portion of potential user queries unanswered,\\nleading to a critical gap in real-world applicability.\\nSo, what is Table Augmented Generation (TAG) and How it addresses some of these\\nchallenges?\\nTable Augmented Generation (TAG)\\nTAG is a new augmentation approach that researchers from Stanford and Berkeley\\nare proposing to address the limitations in Text2SQL approach. Here’s a link to\\ntheir paper: https://arxiv.org/abs/2408.14717\\nHere’s how it works:\\nQuery Synthesis: First, the user’s natural language request is translated into\\nan executable database query. Unlike Text2SQL, TAG can generate more than\\njust SQL queries; it can synthesize complex queries that combine multiple\\ndata sources and types. For example, notice this image that the researchers\\nprovided\\nTranslate to'), Document(metadata={'source': 'lotus.pdf', 'page': 4, 'page_label': '5', 'start_index': 0}, page_content=\"TAG Query Synthesis. Source: https://arxiv.org/abs/2408.14717\\nNotice how the user query “Summarize the reviews of the highest grossing romance\\nmovie considered a ‘classic’” has been translated into:\\nWITH CRM AS (SELECT * FROM movies WHERE genre = 'Romance'\\nAND LLM('{movie_title} is a classic') = 'True')\\nSELECT * FROM CRM \\nWHERE revenue = (SELECT MAX(revenue) FROM CRM);\\nTAG introduced a new LLM call using the line LLM(‘{movie_title} is a classic’) =\\n‘True’). This is the “Augmentation” step. The SQL query or more specifically the\\nTranslate to\"), Document(metadata={'source': 'lotus.pdf', 'page': 5, 'page_label': '6', 'start_index': 0}, page_content='table retrieval step has been augmented with this step because the table does not\\nprovide the context about when a movie is considered “classic”\\n2. Query Execution: Once the query is synthesized, it is executed against the\\ndatabase. TAG leverages the computational power of databases to efficiently handle\\nlarge-scale data retrieval and exact computations, which language models struggle to\\nperform.\\n3. Answer Generation: In this final step, the AI model uses the retrieved data to\\ngenerate a context-rich answer. The model combines world knowledge, semantic\\nreasoning, and domain-specific understanding based on the augmentation in step 1,\\nto produce a comprehensive response to the user’s question.\\nAnother key component that enables TAG to function effectively is the LOTUS\\nframework.\\nLOTUS: The Framework Powering TAG’s Capabilities\\nAs I mentioned above, In order for TAG to work, we need a robust framework that\\ncan seamlessly integrate AI capabilities with traditional database systems. This is\\nwhere LOTUS (Leveraging Optimization Techniques for Unifying Semantic\\nQueries) comes into play. LOTUS is designed to bridge the gap between the\\nreasoning power of large language models (LLMs) and the computational strength of\\ndatabases, enabling more complex and meaningful data queries.\\nWhat is LOTUS?\\nLOTUS is a novel framework that empowers TAG by enabling semantic queries\\nover tables containing both structured and unstructured data. It integrates LLMs\\ndirectly into the database query processing pipeline, combining the best of both\\nworlds — high-performance data management from databases and advanced\\nreasoning and natural language understanding from AI models.\\nKey Features of LOTUS:\\nTranslate to'), Document(metadata={'source': 'lotus.pdf', 'page': 6, 'page_label': '7', 'start_index': 0}, page_content='Semantic Operators for AI-Enhanced Queries: LOTUS introduces a range\\nof semantic operators — AI-based functions that can perform tasks such as\\nfiltering, ranking, and aggregation using natural language processing. For\\ninstance, instead of a traditional SQL filter, a LOTUS query might use a\\nlanguage model to determine which rows contain positive sentiment or\\nrelevant entities, bringing a whole new level of sophistication to querying.\\nOptimized Query Execution: LOTUS is built with an optimized semantic\\nquery execution engine that can handle complex queries more efficiently by\\nbatching LLM operations and integrating them into the database’s native\\nquery processing. This reduces latency and improves performance, making it\\npossible to answer more complex questions quickly.\\nFlexibility and Customization: The framework allows developers to build\\ncustom pipelines that blend traditional SQL operations with advanced AI\\ncapabilities. For example, in a financial services use case, LOTUS could\\nenable a query that not only retrieves historical stock data but also analyzes\\nrecent news sentiment to provide insights into potential future movements —\\nall in one go.\\nEnabling the TAG Framework: LOTUS serves as the backbone for\\nimplementing the TAG model by supporting multi-step, complex queries that\\nrequire both database computations and LLM reasoning. It allows the TAG\\nframework to go beyond standard SQL or retrieval-augmented methods,\\ndelivering more comprehensive answers that are grounded in both data and\\nexternal knowledge.\\nMore on LOTUS can be found here: https://github.com/TAG-Research/lotus\\nThere are some excellent examples in the GitHub link on how to use LOTUS for\\nperforming semantic joins. I’m planning to try it out soon — stay tuned for more in a\\nfuture post!\\nThanks for reading :)\\nTranslate to'), Document(metadata={'source': 'lotus.pdf', 'page': 7, 'page_label': '8', 'start_index': 0}, page_content='If you liked the post, please clap and follow me on Medium and LinkedIn! You can\\nalso book a 1:1 with me here: https://topmate.io/pavan_k_emani\\nIn Plain English 🚀\\nThank you for being a part of the In Plain English community! Before you go:\\nBe sure to clap and follow the writer  👏  \\nFollow us: X | LinkedIn | YouTube | Discord | Newsletter\\nVisit our other platforms: CoFeed | Differ\\nMore content at PlainEnglish.io\\nRecommended from ReadMedium\\nAustin Starks\\nI used OpenAI’s o1 model to develop a trading strategy. It is\\nDESTROYING the market\\nIt literally took one try. I was shocked.\\n8 min read\\nIsaak Kamau\\nA Simple Guide to DeepSeek R1: Architecture, Training, Local\\nDeployment, and Hardware Requirements\\nDeepSeek’s Novel Approach to LLM Reasoning\\n7 min read\\nGenai Llm Machine Learning AI Sql\\nTranslate to'), Document(metadata={'source': 'lotus.pdf', 'page': 8, 'page_label': '9', 'start_index': 0}, page_content='Christopher Tao\\nDo Not Use LLM or Generative AI For These Use Cases\\nChoose correct AI techniques for the right use case families\\n7 min read\\nAlberto Romero\\nDeepSeek Is Chinese But Its AI Models Are From Another Planet\\nOpenAI and the US are in deep trouble\\n13 min read\\nJim Clyde Monge\\nHow To Install And Use DeepSeek R-1 In Your Local PC\\nHere’s a step-by-step guide on how you can run DeepSeek R-1 on your local machine even\\nwithout internet connection.\\n7 min read\\nKenny Vaneetvelde\\nWant to Build AI Agents? Tired of LangChain, CrewAI, AutoGen & Other\\nAI Frameworks? Read this!\\nFrameworks like LangChain, CrewAI, and AutoGen have gained popularity by promising high-\\nlevel abstractions for building AI systems. Yet…\\n17 min read\\nFree OpenAI o1 chat Try OpenAI o1 API\\nTranslate to')]\n"
     ]
    }
   ],
   "source": [
    "#Separar em chunks\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 4000,\n",
    "    chunk_overlap = 20,\n",
    "    length_function = len,\n",
    "    add_start_index = True\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(pages)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storages\n",
    "db = Chroma.from_documents(chunks, embedding=embedding_model, persist_directory=\"naiveDB2\")\n",
    "\n",
    "vector_db = Chroma(persist_directory=\"naiveDB2\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['ea8e33f3-0766-401e-8ec7-5887baa85fa3', 'b74267ca-72ab-4f3e-a45c-d90d58cd7bbb', '143bc5e3-20c2-428e-b3ec-3dc46c2f96ba', '74ff5533-087b-431d-9ed8-e07d63aadead', 'b178aff5-be43-4c9e-af6e-3f296cfd6ecd', 'f5a96d0f-5abb-4378-833b-f3e0ff85a7c7', '62f924e7-1ab6-4ad8-8021-7b02dc016ab6', 'bbdb3a71-22af-498c-ab8d-311d196d8a0d', 'cbb55b68-1f6e-421c-ac5c-722f7ec33986'], 'embeddings': None, 'documents': ['Pavan Emani\\nSummary\\nThe article discusses the transition from Text2SQL and Retrieval-Augmented\\nGeneration (RAG) to Table-Augmented Generation (TAG) as a more effective\\nmethod for AI-driven data queries, leveraging the LOTUS framework to integrate\\nAI and database capabilities.\\nAbstract\\nThe article \"Goodbye, Text2SQL: Why Table-Augmented Generation (TAG) is\\nthe Future of AI-Driven Data Queries!\" explores the limitations of current AI\\nmethods like Text2SQL and Retrieval-Augmented Generation (RAG) in handling\\ncomplex data queries. It argues that TAG, a new approach developed by\\nresearchers from Stanford and Berkeley, overcomes these limitations by\\ncombining AI\\'s semantic reasoning with the computational power of databases.\\nTAG utilizes a multi-step process involving query synthesis, execution, and\\nanswer generation, enhanced by the LOTUS framework, which allows for\\nsemantic queries over structured and unstructured data. This integration enables\\nmore sophisticated and context-rich responses to user queries, addressing the\\ncritical gap in real-world applicability of AI in data analysis.\\nOpinions\\nText2SQL and RAG methods are inadequate for complex queries, as they\\neither translate queries into SQL or perform simple lookups without capturing\\nreal-world complexity.\\nThe inability of existing methods to effectively combine AI reasoning with\\ndatabase computational power is a major bottleneck for deriving actionable\\ninsights from data.\\nTAG is presented as a superior alternative, capable of generating complex\\nqueries that incorporate multiple data sources and types, and performing\\nadvanced operations like sentiment analysis.\\nSearch Translate to English', \"Use the OpenAI o1 models for free at OpenAI01.net (10 times a day for free)!\\nGoodbye, Text2SQL: Why Table-Augmented\\nGeneration (TAG) is the Future of AI-Driven Data\\nQueries!\\nExploring the Future of Natural Language Queries with Table-\\nAugmented Generation.\\nThe LOTUS framework is crucial for TAG's effectiveness, as it integrates AI\\ncapabilities with database systems, enabling semantic queries and optimized\\nquery execution.\\nThe author believes that TAG, powered by LOTUS, represents a significant\\nadvancement in AI-driven data querying, offering flexibility, customization,\\nand the ability to provide comprehensive answers.\\nTranslate to\", 'Photo by Choong Deng Xiang on Unsplash\\nImagine you’re a business analyst, trying to understand why your company’s sales\\ndropped last quarter. You query your database with a simple natural language\\nquestion: “Why did sales drop last quarter?” The ideal scenario would be that the AI\\nsystem instantly provides you with a context-rich, insightful answer — something\\nthat ties together all relevant data points, trends, and market insights. However, the\\nreality is far from ideal.\\nCurrent AI methods for querying databases, such as Text2SQL and Retrieval-\\nAugmented Generation (RAG), fall significantly short. These models are limited by\\ntheir design, either only interpreting natural language as SQL queries or relying on\\nsimple lookups that fail to capture the complexity of real-world questions.\\nWhy does this matter? Using Natural Language to query SQL databases is the new\\nnorm ever since LLMs started capturing the limelight! Businesses today are\\ndrowning in data but starving for insights. The inability of existing methods to\\neffectively leverage both AI’s semantic reasoning and databases’ computational\\npower is a major bottleneck in making data truly actionable. It’s clear that we need a\\nnew approach — one that can understand and answer the wide range of questions\\nreal users want to ask.\\nBut using Natural language in such a scenario comes with challenges:\\nText2SQL: This approach is designed to convert natural language questions into\\nSQL queries. While it works well for straightforward questions like “What were\\nthe total sales last quarter?” it fails when questions require more complex\\nreasoning or knowledge that is not explicitly stored in the database. For example,\\na question like “Which customer reviews of product X are positive?” requires\\nsentiment analysis over text data — a capability outside the scope of SQL\\nqueries.\\nRetrieval-Augmented Generation (RAG): RAG models attempt to use AI to\\nfind relevant data records from a database, but they are limited to point lookups\\nand cannot handle complex computations. They often fail to provide accurate\\nTranslate to', 'answers when data volume is high, or when the question requires reasoning over\\nmultiple data points.\\nConsider a business scenario where you need to understand trends from customer\\nreviews, sales data, and market sentiment all at once. Text2SQL cannot handle free-\\ntext data. And not to forget hallucinations! RAG addresses this to some extent, but its\\ninefficient with large datasets and can provide inaccurate or incomplete answers,\\nespecially when it doesn’t have the knowledge of target database or it cannot exactly\\ntranslate the user intent into a functioning SQL!\\nAnd so, these approaches leave a large portion of potential user queries unanswered,\\nleading to a critical gap in real-world applicability.\\nSo, what is Table Augmented Generation (TAG) and How it addresses some of these\\nchallenges?\\nTable Augmented Generation (TAG)\\nTAG is a new augmentation approach that researchers from Stanford and Berkeley\\nare proposing to address the limitations in Text2SQL approach. Here’s a link to\\ntheir paper: https://arxiv.org/abs/2408.14717\\nHere’s how it works:\\nQuery Synthesis: First, the user’s natural language request is translated into\\nan executable database query. Unlike Text2SQL, TAG can generate more than\\njust SQL queries; it can synthesize complex queries that combine multiple\\ndata sources and types. For example, notice this image that the researchers\\nprovided\\nTranslate to', \"TAG Query Synthesis. Source: https://arxiv.org/abs/2408.14717\\nNotice how the user query “Summarize the reviews of the highest grossing romance\\nmovie considered a ‘classic’” has been translated into:\\nWITH CRM AS (SELECT * FROM movies WHERE genre = 'Romance'\\nAND LLM('{movie_title} is a classic') = 'True')\\nSELECT * FROM CRM \\nWHERE revenue = (SELECT MAX(revenue) FROM CRM);\\nTAG introduced a new LLM call using the line LLM(‘{movie_title} is a classic’) =\\n‘True’). This is the “Augmentation” step. The SQL query or more specifically the\\nTranslate to\", 'table retrieval step has been augmented with this step because the table does not\\nprovide the context about when a movie is considered “classic”\\n2. Query Execution: Once the query is synthesized, it is executed against the\\ndatabase. TAG leverages the computational power of databases to efficiently handle\\nlarge-scale data retrieval and exact computations, which language models struggle to\\nperform.\\n3. Answer Generation: In this final step, the AI model uses the retrieved data to\\ngenerate a context-rich answer. The model combines world knowledge, semantic\\nreasoning, and domain-specific understanding based on the augmentation in step 1,\\nto produce a comprehensive response to the user’s question.\\nAnother key component that enables TAG to function effectively is the LOTUS\\nframework.\\nLOTUS: The Framework Powering TAG’s Capabilities\\nAs I mentioned above, In order for TAG to work, we need a robust framework that\\ncan seamlessly integrate AI capabilities with traditional database systems. This is\\nwhere LOTUS (Leveraging Optimization Techniques for Unifying Semantic\\nQueries) comes into play. LOTUS is designed to bridge the gap between the\\nreasoning power of large language models (LLMs) and the computational strength of\\ndatabases, enabling more complex and meaningful data queries.\\nWhat is LOTUS?\\nLOTUS is a novel framework that empowers TAG by enabling semantic queries\\nover tables containing both structured and unstructured data. It integrates LLMs\\ndirectly into the database query processing pipeline, combining the best of both\\nworlds — high-performance data management from databases and advanced\\nreasoning and natural language understanding from AI models.\\nKey Features of LOTUS:\\nTranslate to', 'Semantic Operators for AI-Enhanced Queries: LOTUS introduces a range\\nof semantic operators — AI-based functions that can perform tasks such as\\nfiltering, ranking, and aggregation using natural language processing. For\\ninstance, instead of a traditional SQL filter, a LOTUS query might use a\\nlanguage model to determine which rows contain positive sentiment or\\nrelevant entities, bringing a whole new level of sophistication to querying.\\nOptimized Query Execution: LOTUS is built with an optimized semantic\\nquery execution engine that can handle complex queries more efficiently by\\nbatching LLM operations and integrating them into the database’s native\\nquery processing. This reduces latency and improves performance, making it\\npossible to answer more complex questions quickly.\\nFlexibility and Customization: The framework allows developers to build\\ncustom pipelines that blend traditional SQL operations with advanced AI\\ncapabilities. For example, in a financial services use case, LOTUS could\\nenable a query that not only retrieves historical stock data but also analyzes\\nrecent news sentiment to provide insights into potential future movements —\\nall in one go.\\nEnabling the TAG Framework: LOTUS serves as the backbone for\\nimplementing the TAG model by supporting multi-step, complex queries that\\nrequire both database computations and LLM reasoning. It allows the TAG\\nframework to go beyond standard SQL or retrieval-augmented methods,\\ndelivering more comprehensive answers that are grounded in both data and\\nexternal knowledge.\\nMore on LOTUS can be found here: https://github.com/TAG-Research/lotus\\nThere are some excellent examples in the GitHub link on how to use LOTUS for\\nperforming semantic joins. I’m planning to try it out soon — stay tuned for more in a\\nfuture post!\\nThanks for reading :)\\nTranslate to', 'If you liked the post, please clap and follow me on Medium and LinkedIn! You can\\nalso book a 1:1 with me here: https://topmate.io/pavan_k_emani\\nIn Plain English 🚀\\nThank you for being a part of the In Plain English community! Before you go:\\nBe sure to clap and follow the writer  👏  \\nFollow us: X | LinkedIn | YouTube | Discord | Newsletter\\nVisit our other platforms: CoFeed | Differ\\nMore content at PlainEnglish.io\\nRecommended from ReadMedium\\nAustin Starks\\nI used OpenAI’s o1 model to develop a trading strategy. It is\\nDESTROYING the market\\nIt literally took one try. I was shocked.\\n8 min read\\nIsaak Kamau\\nA Simple Guide to DeepSeek R1: Architecture, Training, Local\\nDeployment, and Hardware Requirements\\nDeepSeek’s Novel Approach to LLM Reasoning\\n7 min read\\nGenai Llm Machine Learning AI Sql\\nTranslate to', 'Christopher Tao\\nDo Not Use LLM or Generative AI For These Use Cases\\nChoose correct AI techniques for the right use case families\\n7 min read\\nAlberto Romero\\nDeepSeek Is Chinese But Its AI Models Are From Another Planet\\nOpenAI and the US are in deep trouble\\n13 min read\\nJim Clyde Monge\\nHow To Install And Use DeepSeek R-1 In Your Local PC\\nHere’s a step-by-step guide on how you can run DeepSeek R-1 on your local machine even\\nwithout internet connection.\\n7 min read\\nKenny Vaneetvelde\\nWant to Build AI Agents? Tired of LangChain, CrewAI, AutoGen & Other\\nAI Frameworks? Read this!\\nFrameworks like LangChain, CrewAI, and AutoGen have gained popularity by promising high-\\nlevel abstractions for building AI systems. Yet…\\n17 min read\\nFree OpenAI o1 chat Try OpenAI o1 API\\nTranslate to'], 'uris': None, 'data': None, 'metadatas': [{'page': 0, 'page_label': '1', 'source': 'lotus.pdf', 'start_index': 0}, {'page': 1, 'page_label': '2', 'source': 'lotus.pdf', 'start_index': 0}, {'page': 2, 'page_label': '3', 'source': 'lotus.pdf', 'start_index': 0}, {'page': 3, 'page_label': '4', 'source': 'lotus.pdf', 'start_index': 0}, {'page': 4, 'page_label': '5', 'source': 'lotus.pdf', 'start_index': 0}, {'page': 5, 'page_label': '6', 'source': 'lotus.pdf', 'start_index': 0}, {'page': 6, 'page_label': '7', 'source': 'lotus.pdf', 'start_index': 0}, {'page': 7, 'page_label': '8', 'source': 'lotus.pdf', 'start_index': 0}, {'page': 8, 'page_label': '9', 'source': 'lotus.pdf', 'start_index': 0}], 'included': [<IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
     ]
    }
   ],
   "source": [
    "naive_retreiver = vector_db.as_retriever(search_kwargs={\"k\":10})\n",
    "print(vector_db.get())\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = \"\"\n",
    "\n",
    "rerank = CohereRerank(top_n=3, model=\"rerank-v3.5\")\n",
    "\n",
    "compressor_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=rerank,\n",
    "    base_retriever=naive_retreiver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "    Você é um especialista em inteligência artificial. Responda a pergunta abaixo utilizando o contexto informado.\n",
    "    Query:\n",
    "    {question}\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(TEMPLATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_retrieval = RunnableParallel({\"question\": RunnablePassthrough(), \"context\": compressor_retriever})\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor_chain_retriever = setup_retrieval | rag_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 10 is greater than number of elements in index 9, updating n_results = 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Aqui está um resumo do contexto:\\n\\nO contexto discute a limitação dos métodos atuais de inteligência artificial (IA) para consultar bancos de dados, como Text2SQL e Retrieval-Augmented Generation (RAG). Esses métodos têm dificuldade em lidar com perguntas complexas que requerem raciocínio semântico e conhecimento não explícito nos bancos de dados.\\n\\nPara superar essas limitações, é apresentado o framework LOTUS (Leveraging Optimization Techniques for Unifying Semantic Queries), que integra modelos de linguagem grande (LLMs) diretamente no pipeline de processamento de consultas de banco de dados. Isso permite que as consultas sejam realizadas de forma mais complexa e significativa, combinando a capacidade de raciocínio dos LLMs com a força computacional dos bancos de dados.\\n\\nO framework LOTUS é utilizado pelo sistema TAG (Table Augmentation Generation), que consiste em três etapas:\\n\\n1. Síntese de consultas: a pergunta do usuário é traduzida em uma consulta SQL.\\n2. Execução de consultas: a consulta é executada contra o banco de dados.\\n3. Geração de respostas: o modelo de IA usa os dados recuperados para gerar uma resposta rica em contexto.\\n\\nO objetivo do framework LOTUS e do sistema TAG é permitir que os usuários façam perguntas complexas e recebam respostas precisas e significativas, superando as limitações dos métodos atuais de IA para consultar bancos de dados.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressor_chain_retriever.invoke(\"Faça um resumo do contexto?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
